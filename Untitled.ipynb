{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear algebra\n",
    "import numpy as np\n",
    " \n",
    "# data processing\n",
    "import pandas as pd\n",
    " \n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    " \n",
    "# Algorithms\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve, auc, make_scorer, confusion_matrix, f1_score, fbeta_score, roc_auc_score\n",
    "# Import the Naive Bayes, logistic regression, Bagging, RandomForest, AdaBoost, GradientBoost, Decision Trees and SVM Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"training_data.csv\")\n",
    "test = pd.read_csv(\"testing_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3000.000000\n",
       "mean      502.675667\n",
       "std        87.217854\n",
       "min       195.000000\n",
       "25%       445.000000\n",
       "50%       505.000000\n",
       "75%       565.000000\n",
       "max       795.000000\n",
       "Name: Logical, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Logical.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2', '1', '3', '4'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Specialization.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Specialization'].replace(['computer application','computer science & engineering','computer engineering','information technology','information science engineering','information & communication technology','computer science and technology'], '1', inplace = True)\n",
    "test['Specialization'].replace(['electronics and communication engineering','telecommunication engineering', 'electrical engineering','electronics & instrumentation eng','electronics & telecommunications','electronics engineering','electronics and instrumentation engineering','electronics and electrical engineering','applied electronics and instrumentation','control and instrumentation engineering','instrumentation and control engineering' ], '2', inplace = True)\n",
    "test['Specialization'].replace(['industrial & production engineering', 'internal combustion engine','mechanical engineering','mechatronics', 'automobile/automotive engineering','mechanical and automation','aeronautical engineering','mechanical & production engineering','metallurgical engineering','industrial engineering'], '3', inplace = True)\n",
    "test['Specialization'].replace(['civil engineering','biotechnology', 'other','chemical engineering', 'polymer technology','biomedical engineering','industrial & management engineering'], '4', inplace = True)\n",
    "test['Specialization'].fillna('4',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test[test.JobCity == '-1'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum()\n",
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_na = train.isna().sum()/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group_by_city = train.groupby(['JobCity'])\n",
    "group_by_city = test.groupby(['JobCity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop_index_jobcity = train[train['JobCity'] == '-1'].index\n",
    "drop_index_jobcity_test = test[test['JobCity'] == '-1'].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.drop(drop_index_jobcity, inplace = True)\n",
    "test.drop(drop_index_jobcity_test, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train = train.reset_index()\n",
    "test = test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['JobCity'] = train['JobCity'].str.lower()\n",
    "test['JobCity'] = test['JobCity'].str.lower() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['JobCity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['YOB'] = train['DOB'].str[:4]\n",
    "test['YOB'] = test['DOB'].str[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['YOB'] = train['YOB'].astype(int)\n",
    "test['YOB'] = test['YOB'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_12_yob = train['12graduation'] - train['YOB']\n",
    "diff_12_yob_ = test['12graduation'] - test['YOB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_12_yob.dropna(inplace = True)\n",
    "diff_12_yob_.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_12_yob.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['12graduation'].fillna(train['YOB'] + 18, inplace = True)\n",
    "test['12graduation'].fillna(test['YOB'] + 18, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['12graduation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '2', '4', '3'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Specialization'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Specialization'].replace(['computer application','information science engineering','electronics and computer engineering', 'computer engineering','computer science & engineering', 'information technology','computer science and technology','computer and communication engineering','computer networking','computer science','information & communication technology','information science'], '1', inplace = True)\n",
    "train['Specialization'].replace(['electronics and communication engineering', 'electronics and electrical engineering','electronics & instrumentation eng', 'electronics & telecommunications','electrical engineering','electronics engineering','instrumentation and control engineering','electronics and instrumentation engineering','applied electronics and instrumentation','telecommunication engineering','embedded systems technology','power systems and automation','electrical and power engineering','electronics','instrumentation engineering'], '2', inplace = True)\n",
    "train['Specialization'].replace(['industrial & production engineering', 'mechanical engineering','mechatronics', 'automobile/automotive engineering','mechanical and automation','aeronautical engineering','mechanical & production engineering','metallurgical engineering','industrial engineering'], '3', inplace = True)\n",
    "train['Specialization'].replace(['civil engineering','biotechnology', 'other','chemical engineering', 'polymer technology','biomedical engineering'], '4', inplace = True)\n",
    "train['Specialization'].fillna('4',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['Specialization'],axis = 1, inplace = True)\n",
    "test.drop(['Specialization'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['CollegeCityID'], axis=1, inplace = True)\n",
    "test.drop(['CollegeCityID'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['CollegeID'], axis=1, inplace = True)\n",
    "test.drop(['CollegeID'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['10board'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Gender = train.Gender.map({'m':1, 'f':2})\n",
    "test.Gender = test.Gender.map({'m':1, 'f':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tenth_board_zero = train[train['10board'] == '0'].index\n",
    "tenth_board_zero_ = test[test['10board'] == '0'].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.drop(tenth_board_zero, inplace = True)\n",
    "test.drop(tenth_board_zero_, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['10board'] = train['10board'].astype(\"category\")\n",
    "test['10board'] = test['10board'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['10board'].cat.codes.unique()\n",
    "test['10board'].cat.codes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['10board'] = train['10board'].cat.codes\n",
    "test['10board'] = test['10board'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['12board'] = train['12board'].astype(\"category\")\n",
    "train['12board'] = train['12board'].cat.codes\n",
    "test['12board'] = test['12board'].astype(\"category\")\n",
    "test['12board'] = test['12board'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Degree = train.Degree.astype(\"category\").cat.codes\n",
    "test.Degree = test.Degree.astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.Specialization = train.Specialization.astype(\"category\").cat.codes\n",
    "test.Specialization = test.Specialization.astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.CollegeState = train.CollegeState.astype(\"category\").cat.codes\n",
    "test.CollegeState = test.CollegeState.astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['JobCity'] = train['JobCity'].str.lower()\n",
    "train['JobCity'].replace(['bangalore', 'bangalore ','banglore', 'bangalore','bengaluru',\n",
    "                                            'banagalore', ' bangalore', 'banglore', 'banglore', 'banglore ', 'asifabadbanglore', 'bangalore ','bangalore '], 'bangalore', inplace = True) \n",
    "train['JobCity'].replace(['bhubaneshwar', 'bhubaneswar','bhubneshwar', 'bhubaneswar '], 'bhubaneshwar', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['new delhi', 'delhi',' delhi', 'new delhi ','new dehli'], 'new delhi', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['bhopal', 'bhopal '], 'bhopal', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['sonepat', 'sonipat'], 'sonipat', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['tirupati', 'tirupathi'], 'tirupati', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['hyderabad', 'hyderabad ', 'hyderabad(bhadurpally)','hderabad'], 'hyderabad', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['gurgaon', 'gurgaon ', 'gurga', 'gurgoan', 'guragaon'], 'gurgaon', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['noida', 'greater noida','noida '], 'noida', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['pune', ' pune','pune ','punr'], 'pune', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['muzzafarpur', 'muzaffarpur'], 'muzaffarpur', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['jaipur', 'jaipur '], 'jaipur', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['kanpur', 'kanpur '], 'kanpur', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['nagpur', 'nagpur '], 'nagpur', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['thiruvananthapuram', 'trivandrum','trivandrum '], 'trivandrum', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['vsakhapttnam', 'vizag','vishakhapatnam','visakhapatnam'], 'vizag', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['gandhi nagar','gandhinagar'], 'gandhinagar', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['chennai', 'chennai ',' chennai'], 'chennai', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['delhi/ncr','ncr'], 'ncr', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['trichy','trichur'], 'trichur', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['nasikcity','nashik'], 'nashik', inplace = True)\n",
    "train['JobCity'].replace(['madurai ','madurai'], 'madurai', inplace = True)\n",
    "\n",
    "train['JobCity'].replace([' mumbai','mumbai '], 'mumbai', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['kolkata ','kolkata`'], 'kolkata', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['siliguri '], 'siliguri', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['mysore '], 'mysore', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['rae bareli'], 'bareli', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['ahmedabad '], 'ahmedabad', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['chandigarh '], 'chandigarh', inplace = True)\n",
    "\n",
    "train['JobCity'].replace(['ranchi '], 'ranchi', inplace = True)\n",
    "test['JobCity'] = test['JobCity'].str.lower()\n",
    "test['JobCity'].replace(['bangalore', 'bangalore ','banglore', 'bangalore','bengaluru',\n",
    "                                            'banagalore', ' bangalore', 'banglore', 'banglore', 'banglore ', 'asifabadbanglore', 'bangalore ','bangalore '], 'bangalore', inplace = True) \n",
    "test['JobCity'].replace(['bhubaneshwar', 'bhubaneswar','bhubneshwar', 'bhubaneswar '], 'bhubaneshwar', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['new delhi', 'delhi',' delhi', 'new delhi ','new dehli'], 'new delhi', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['bhopal', 'bhopal '], 'bhopal', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['sonepat', 'sonipat'], 'sonipat', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['tirupati', 'tirupathi'], 'tirupati', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['hyderabad', 'hyderabad ', 'hyderabad(bhadurpally)','hderabad'], 'hyderabad', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['gurgaon', 'gurgaon ', 'gurga', 'gurgoan', 'guragaon'], 'gurgaon', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['noida', 'greater noida','noida '], 'noida', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['pune', ' pune','pune ','punr'], 'pune', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['muzzafarpur', 'muzaffarpur'], 'muzaffarpur', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['jaipur', 'jaipur '], 'jaipur', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['kanpur', 'kanpur '], 'kanpur', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['nagpur', 'nagpur '], 'nagpur', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['thiruvananthapuram', 'trivandrum','trivandrum '], 'trivandrum', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['vsakhapttnam', 'vizag','vishakhapatnam','visakhapatnam'], 'vizag', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['gandhi nagar','gandhinagar'], 'gandhinagar', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['chennai', 'chennai ',' chennai'], 'chennai', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['delhi/ncr','ncr'], 'ncr', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['trichy','trichur'], 'trichur', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['nasikcity','nashik'], 'nashik', inplace = True)\n",
    "test['JobCity'].replace(['madurai ','madurai'], 'madurai', inplace = True)\n",
    "\n",
    "test['JobCity'].replace([' mumbai','mumbai '], 'mumbai', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['kolkata ','kolkata`'], 'kolkata', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['siliguri '], 'siliguri', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['mysore '], 'mysore', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['rae bareli'], 'bareli', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['ahmedabad '], 'ahmedabad', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['chandigarh '], 'chandigarh', inplace = True)\n",
    "\n",
    "test['JobCity'].replace(['ranchi '], 'ranchi', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.JobCity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.JobCity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['JobCity'] = train['JobCity'].astype(\"category\").cat.codes\n",
    "test['JobCity'] = test['JobCity'].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.JobCity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train.JobCity.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.JobCity.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.JobCity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['Unnamed: 0', 'DOB'],axis = 1, inplace = True)\n",
    "test.drop(['Unnamed: 0', 'DOB'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train, test]\n",
    "\n",
    "for dataset in data:\n",
    "    mean = dataset[\"nueroticism\"].mean()\n",
    "    std = dataset[\"nueroticism\"].std()\n",
    "    is_null = dataset[\"nueroticism\"].isnull().sum()\n",
    "    # compute random numbers between the mean, std and is_null\n",
    "    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n",
    "    # fill NaN values in Age column with random values generated\n",
    "    age_slice = dataset[\"nueroticism\"].copy()\n",
    "    age_slice[np.isnan(age_slice)] = rand_age\n",
    "    dataset[\"nueroticism\"] = age_slice\n",
    "    dataset[\"nueroticism\"] = dataset[\"nueroticism\"].astype(int)\n",
    "dataset[\"nueroticism\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train,test]\n",
    "\n",
    "for dataset in data:\n",
    "    mean = dataset[\"conscientiousness\"].mean()\n",
    "    std = dataset[\"conscientiousness\"].std()\n",
    "    is_null = dataset[\"conscientiousness\"].isnull().sum()\n",
    "    # compute random numbers between the mean, std and is_null\n",
    "    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n",
    "    # fill NaN values in Age column with random values generated\n",
    "    age_slice = dataset[\"conscientiousness\"].copy()\n",
    "    age_slice[np.isnan(age_slice)] = rand_age\n",
    "    dataset[\"conscientiousness\"] = age_slice\n",
    "    dataset[\"conscientiousness\"] = dataset[\"conscientiousness\"].astype(int)\n",
    "dataset[\"conscientiousness\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train,test]\n",
    "\n",
    "for dataset in data:\n",
    "    mean = dataset[\"10percentage\"].mean()\n",
    "    std = dataset[\"10percentage\"].std()\n",
    "    is_null = dataset[\"10percentage\"].isnull().sum()\n",
    "    # compute random numbers between the mean, std and is_null\n",
    "    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n",
    "    # fill NaN values in Age column with random values generated\n",
    "    age_slice = dataset[\"10percentage\"].copy()\n",
    "    age_slice[np.isnan(age_slice)] = rand_age\n",
    "    dataset[\"10percentage\"] = age_slice\n",
    "    dataset[\"10percentage\"] = dataset[\"10percentage\"].astype(int)\n",
    "dataset[\"10percentage\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = train.drop('ID', axis=1)\n",
    "X_train = train.drop([\"Salary\"], axis=1)\n",
    "Y_train = train[\"Salary\"]\n",
    "X_test  = test.drop(\"ID\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "sc = StandardScaler()\n",
    "X_test = sc.fit_transform(X_test)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2, random_state=1)\n",
    "principal_components = pca.fit_transform(X_train)\n",
    "plt.scatter(principal_components[:,0],principal_components[:,1], c = Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principal_components = pd.DataFrame(principal_components)\n",
    "drop_index = principal_components[(principal_components[principal_components.columns[0]] > 4.5) | (principal_components[principal_components.columns[1]]>4) | (principal_components[principal_components.columns[1]] < -4) | (principal_components[principal_components.columns[0]] < -4)].index\n",
    "drop_index                                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(drop_index ,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.drop(['level_0','index'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "regression_model = linear_model.LinearRegression()\n",
    "regression_model.fit(X_train, Y_train)\n",
    "Y_pred_train =regression_model.predict(X_test)\n",
    "#rmse = mean_squared_error(Y_train, y_pred_train)\n",
    "#r2 = r2_score(Y_train, y_pred_train)\n",
    "#print('Slope:' ,regression_model.coef_)\n",
    "#print('Intercept:', regression_model.intercept_)\n",
    "#print('Root mean squared error: ', rmse)\n",
    "#print('R2 score: ', r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train = np.round(Y_pred_train,-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = Y_pred_train\n",
    "submission = pd.DataFrame({'ID':test['ID'], 'Salary':predictions})\n",
    "filename = 'kriti_lohit5.csv'\n",
    "submission.to_csv(filename, index = False)\n",
    "print('saved file: ' + filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xg = XGBClassifier()\n",
    "xg.fit(X_train, Y_train)\n",
    "xg_predictions = xg.predict(X_test)\n",
    "Y_pred9 = xg_predictions\n",
    "acc_xg = round(xg.score(X_train, Y_train) * 100, 2)\n",
    "print (acc_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = Y_pred9\n",
    "submission = pd.DataFrame({'ID':test['ID'], 'Salary':predictions})\n",
    "filename = 'kriti_lohit2.csv'\n",
    "submission.to_csv(filename, index = False)\n",
    "print('saved file: ' + filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "param_test1 = {\n",
    "    'n_estimators': [100,200,500,750,1000],\n",
    "    'max_depth': [3,5,7,9],\n",
    "    'min_child_weight': [1,3,5],\n",
    "    'gamma':[i/10.0 for i in range(0,5)],\n",
    "    'subsample':[i/10.0 for i in range(6,10)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "    'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05, 0.1, 1],\n",
    "    'learning_rate': [0.01, 0.02, 0.05, 0.1]\n",
    "}\n",
    "scoring = { 'Accuracy': make_scorer(accuracy_score)}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(), \n",
    "                       param_grid = param_test1, \n",
    "                       scoring=scoring, iid=False,\n",
    "                       cv=5, verbose = 5, \n",
    "                       refit='Accuracy')\n",
    "gsearch1.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our model\n",
    "xg = XGBClassifier(learning_rate=0.01, n_estimators=750,\n",
    "                   max_depth= 3, min_child_weight= 1, \n",
    "                   colsample_bytree= 0.6, gamma= 0.0, \n",
    "                   reg_alpha= 0.01, subsample= 0.8\n",
    "                  )\n",
    "xg.fit(X_train, Y_train)\n",
    "xg_predictions = xg.predict(X_test)\n",
    "Y_pred10 = xg_predictions\n",
    "acc_xg = round(xg.score(X_train, Y_train) * 100, 2)\n",
    "print (acc_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3 = Y_pred10\n",
    "submission = pd.DataFrame({'ID':test['ID'], 'Salary':predictions})\n",
    "filename = 'kriti_lohit3.csv'\n",
    "submission.to_csv(filename, index = False)\n",
    "print('saved file: ' + filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
